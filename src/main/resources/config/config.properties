####################################################################################
#=========================== Flink specific options ===============================#
####################################################################################
# Set parallelism at Flink Execution Environment Level. This parameter concerned parallelism
# for all operators, data source and data sinks.
execution.environment.parallelism=auto

# Set parallelism for Flink Kafka consumer. Recommended value is parallelism == total kafka partitions for all topics.
#Ex : Kafka consumer is set to consume :
#       windows-logs topic with 4 partitions
#       linux-logs topic with 2 partitions
#Then recommended parallelism for Flink consumer is 6.
# For best performances, it's also recommended to have parallelism <= total of CPU cores available on all TaskManagers (Workers)
kafka.consumer.parallelism=auto

####################################################################################
#=========================== Redis specific options ===============================#
####################################################################################
# Redis server IP or DNS name
redis.server.host=localhost

# Redis server port (Default 6379)
redis.server.port=6379

# Redis server connection timeout (in Milliseconds)
redis.server.connection.timeout=3000

# Redis key expiration (in Seconds), default is 84600.
redis.key.expire=86400

# Redis I/O Thread pool size is the number of threads that can be allocated for Redis I/O.
# Minimum I/O Threads are 3. A pool with fewer threads can cause undefined behavior.
# By default should be equal to number of processors
redis.io.threads=8

# Redis Computation Thread pool size is the number of threads that can be allocated for Redis I/O.
# Minimum Computation Threads are 3. A pool with fewer threads can cause undefined behavior.
# By default should be equal to number of processors
redis.compute.threads=8

# Redis Pool Maximum number of milliseconds that a caller need to wait when no connection is available (-1 for unlimited).
# Because event stream can be huge, if MaxWait is too high, this can increase the out-of-order number of event.
redis.pool.maxwait=1000

# Redis Pool connections validation with the ping command before they are borrowed from the pool.
# If connection turns out to be invalid, it will be removed from the pool
redis.pool.testonborrow=false 

# Redis Pool connections validation with the ping command before they are returned to the pool.
# If connection turns out to be invalid, it will be removed from the pool
redis.pool.testonreturn=false

# Redis Pool enable idle resource detection.
redis.pool.testwhileidle=true

####################################################################################
#=========================== Kafka specific options ===============================#
####################################################################################
# Kafka server(s) IP address(es) or DNS name(s) for consumer.
bootstrap.servers.ip=localhost

# Kafka server(s) network port.
bootstrap.servers.port=9092

# Kafka group.id for consumer.
group.id=flink_kafka_consumer

# Specify which Kafka topics to consume to get security events. It's possible to use a comma separated topic list or
# a pattern for topics name like ".*-logs$" to consume all topics with name ending with "-logs".
topic.name.list=windows-logs,linux-logs,zeek-logs

#topic.name.regex=.*-logs$
# Specify the Kafka consumer start position. Value can be :
#       - setStartFromEarliest;     => start from the earliest record possible
#       - setStartFromLatest;       => start from the latest record
#       - setStartFromTimestamp; => start from specified epoch timestamp (milliseconds)
#       - setStartFromGroupOffsets; => the default behaviour
start.position=setStartFromGroupOffsets

# For setStartFromTimestamp, start timestamp need to be specified in epoch (milliseconds) format.
#start.timestamp=0

####################################################################################
#======================= Elasticsearch specific options ===========================#
####################################################################################
# Elasticsearch server address
elasticsearch.host=192.168.1.202

# Elasticsearch server port
elasticsearch.port=9200

# Elasticsearch access thought HTTP or HTTPS
elasticsearch.proto=http

# Elasticsearch index name for security events
elasticsearch.event.index=events-

# Elasticsearch index name for alerts
elasticsearch.alert.index=alerts-

# Set the timeout for the REST Client of Flink Elasticsearch Connector.
# Default value for Request, Connect and Socket are 1, 30 and 30 seconds. When the Heap memory for the Elasticsearch instance is to low/small
# REST request can experience timeout. You can increment the timeout of value for REST client with the following parameters.
# Set REST Client RequestTimeOut (in Milliseconds)
elasticsearch.rest.request.timeout=60000

# Set REST Client ConnectTimeOut (in Milliseconds)
elasticsearch.rest.connect.timeout=30000

# Set REST Client SocketTimeOut (in Milliseconds)
elasticsearch.rest.socket.timeout=60000

# Set the number of element that will be buffered before being emit by the ElasticsearchSink for event indexes.
elasticsearch.event.bulkflushmaxactions=1

# Set the number of element that will be buffered before being emit by the ElasticsearchSink for alert indexes.
# 1 means that alerts are not buffered and emitted directly.
elasticsearch.alert.bulkflushmaxactions=1

# Set ElasticsearchSink parallelism for Alert stream.
elasticsearch.alert.streamparallelism=4

# Set ElasticsearchSink parallelism for Event stream.
elasticsearch.event.streamparallelism=6

####################################################################################
#======================== Sigma rules specific options ============================#
####################################################################################
# Sigma rules folder path
rules.folder=./src/main/resources/SigmaRules/
# Sigma global mapping file path
global.map=./src/main/resources/sigma_ECS_fields_map.json
# Sigma specific mapping files folder path
maps.folder=./src/main/resources/SigmaMaps/

####################################################################################
#============================ MISP specific options ===============================#
####################################################################################
# Set to TRUE to enable enrichment with MISP.
# /!\ MISP server need to be reachable and it's mandatory to set "misp.host", "misp.ssl.enable", "misp.automation.key" and "misp.map".
misp.enrichment=true
# MISP server hostname or IP address
# /!\ If https is used, misp.host value need to match CN or Alternate name from MISP certificate because certificates must be added in Java keystore.
misp.host=nybble-security.nybble.local
# Specify if MISP is accessed thought http or https. Default is true, so https is used.
misp.ssl.enable=true
# MISP Automation API Key
misp.automation.key=tpjP7Q60mdWqdZaWaqeeBVxr61yMyeBlRv7WKSor
# MISP attributes type and fields mapping file. This file specify which attributes need to be used to enrich fields by using event tags.
# For example field "destination.ip" can be enrich from attributes with type "ip-dst" from events with tag "C2-IP" or "TOR-node"
# In order to get attributes value, corresponding event need to be tags in MISP. Then the tag need to be added in the map file with attributes type to use for enrichment.
# You can find all attributes type in MISP Documentation here : https://www.misp-project.org/datamodels/
misp.map=./src/main/resources/MISPMaps/event_attributes_map.json